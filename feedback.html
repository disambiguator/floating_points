<html>
<head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/104/three.min.js"></script>
</head>
<body>

<video id="video" autoplay="true" style="display:none">
</video>

<script id="fragShader" type="shader-code">
		uniform vec2 res;//The width and height of our screen
		uniform sampler2D bufferTexture;//Our input texture
		uniform sampler2D videoTexture;
		uniform float time;
		void main() {
			vec2 st = gl_FragCoord.xy / res;
			vec2 uv = st * 0.9985;
			vec4 sum = texture2D(bufferTexture, uv);
			vec4 src = texture2D(videoTexture, uv);
			sum.rgb = mix(sum.rbg, src.rgb, 0.01);
			gl_FragColor = sum;

		 }

</script>
<script>
  var scene;
  var camera;
  var renderer;
  var bufferScene;
  var textureA;
  var textureB;
  var bufferMaterial;
  var quad;
  var video;
  var videoTexture;

  const constraints = {
    video: { width: { exact: 640 }, height: { exact: 480 } }
  }

  function sceneSetup () {
    scene = new THREE.Scene();
    var width = window.innerWidth;
    var height = window.innerHeight;
    camera = new THREE.OrthographicCamera(width / -2, width / 2, height / 2, height / -2, 1, 1000);
    camera.position.z = 2;
    renderer = new THREE.WebGLRenderer();
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);
  }

  function videoTextureSetup () {
    video = document.getElementById('video');

    navigator.mediaDevices.getUserMedia(constraints)
      .then((stream) => (video.srcObject = stream))

    // setInterval(this.captureImage, 50)

    videoTexture = new THREE.VideoTexture(video);
    videoTexture.minFilter = THREE.LinearFilter;
    videoTexture.magFilter = THREE.LinearFilter;
    videoTexture.format = THREE.RGBFormat;
  }

  function bufferTextureSetup () {
    //Create buffer scene
    bufferScene = new THREE.Scene();
    //Create 2 buffer textures
    textureA = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, {
      minFilter: THREE.LinearFilter,
      magFilter: THREE.LinearFilter
    });
    textureB = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, {
      minFilter: THREE.LinearFilter,
      magFilter: THREE.LinearFilter
    });
    //Pass textureA to shader
    bufferMaterial = new THREE.ShaderMaterial({
      uniforms: {
        bufferTexture: { type: "t", value: textureA.texture },
        res: { type: 'v2', value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
        //Keeps the resolution
        videoTexture: { type: "t", value: videoTexture },
        time: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI }
      },
      fragmentShader: document.getElementById('fragShader').innerHTML
    });
    const plane = new THREE.PlaneBufferGeometry(window.innerWidth, window.innerHeight);
    const bufferObject = new THREE.Mesh(plane, bufferMaterial);
    bufferScene.add(bufferObject);
    //Draw textureB to screen
    const finalMaterial = new THREE.MeshBasicMaterial({ map: textureB });
    quad = new THREE.Mesh(plane, finalMaterial);
    scene.add(quad);
  }

  //Initialize the Threejs scene
  sceneSetup();
  //Setup the frame buffer/texture we're going to be rendering to instead of the screen
  videoTextureSetup();
  bufferTextureSetup();

  function render () {
    requestAnimationFrame(render);
    //Draw to textureB
    renderer.setRenderTarget(textureB);
    renderer.render(bufferScene, camera);

    //Swap textureA and B
    var t = textureA;
    textureA = textureB;
    textureB = t;
    quad.material.map = textureB.texture;
    bufferMaterial.uniforms.bufferTexture.value = textureA.texture;
    //Update time
    bufferMaterial.uniforms.time.value += 0.01;
    //Finally, draw to the screen
    renderer.setRenderTarget(null);
    renderer.render(scene, camera);
  }

  render();
</script>
</body>
</html>
